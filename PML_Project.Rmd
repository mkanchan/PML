---
title: "Practical Machine Learning Project"
author: "Mukesh Kanchan"
date: "Wednesday, September 17, 2014"
output: html_document
---

##Overview

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement Â- a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks.

One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this data set, the participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants toto predict the manner in which praticipants did the exercise.

The dependent variable or response is the "classe" variable in the training set.

##Data
Download and load the data
```{r cache=FALSE}
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "./PML/pml-training.csv")
#download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "./PML/pml-testing.csv")


trainingOrg = read.csv("pml-training.csv", na.strings=c("", "NA", "NULL"))
# data.train =  read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", na.strings=c("", "NA", "NULL"))

testingOrg = read.csv("pml-testing.csv", na.strings=c("", "NA", "NULL"))
dim(trainingOrg)
dim(testingOrg)
```

##Process data

Reduce the number of predictors:

1. Remove variable with high NAs
```{r cache=FALSE}
training.dena <- trainingOrg[ , colSums(is.na(trainingOrg)) == 0]
#head(training1)
#training3 <- training.decor[ rowSums(is.na(training.decor)) == 0, ]
dim(training.dena)
```

2. Remove irrelevent variables
```{r cache=FALSE}
remove = c('X', 'user_name', 'raw_timestamp_part_1', 'raw_timestamp_part_2', 'cvtd_timestamp', 'new_window', 'num_window')
training.dere <- training.dena[, -which(names(training.dena) %in% remove)]
dim(training.dere)
```
3. Variables with extremely low variance
```{r cache=FALSE}
library(caret)
zeroVar= nearZeroVar(training.dere[sapply(training.dere, is.numeric)], saveMetrics = TRUE)
training.nonzerovar = training.dere[,zeroVar[, 'nzv']==0]
dim(training.nonzerovar)
```
4. Highly coorelated variables
```{r cache=FALSE}
corrMatrix <- cor(na.omit(training.nonzerovar[sapply(training.nonzerovar, is.numeric)]))
dim(corrMatrix)
corrDF <- expand.grid(row = 1:52, col = 1:52)
corrDF$correlation <- as.vector(corrMatrix)
levelplot(correlation ~ row+ col, corrDF)
removecor = findCorrelation(corrMatrix, cutoff = .90, verbose = FALSE)
training.decor = training.nonzerovar[,-removecor]
dim(training.decor)
```

Split data to training and testing for cross validation.

```{r cache=FALSE}
inTrain <- createDataPartition(y=training.decor$classe, p=0.7, list=FALSE)
training <- training.decor[inTrain,]; testing <- training.decor[-inTrain,]
dim(training);dim(testing)
```
##Analysis
1. Regression Tree
```{r cache=FALSE}
library(tree)
set.seed(12345)
tree.training=tree(classe~.,data=training)
plot(tree.training)
text(tree.training,pretty=0, cex =.8)
```

2. Cross Validation
Lets check the performance of tree on testing data by cross validation

```{r cache=TRUE}
modFit <- train(classe ~ .,method="rpart",data=training)
tree.pred=predict(tree.training,testing,type="class")
predMatrix = with(testing,table(tree.pred,classe))
sum(diag(predMatrix))/sum(as.vector(predMatrix))
```
This is not very accurate.


```{r cache=FALSE}
tree.pred=predict(modFit,testing)
predMatrix = with(testing,table(tree.pred,classe))
sum(diag(predMatrix))/sum(as.vector(predMatrix))
```

This from 'caret' package is much lower than the result from 'tree' package.

3. Purning Tree
Use cross validation to purne the heavy/dip branches

```{r cache=FALSE}
cv.training=cv.tree(tree.training,FUN=prune.misclass)
cv.training
plot(cv.training)
```

It shows that when the size of the tree goes down, the deviance goes up. It means the 21 is a good size (i.e. number of terminal nodes) for this tree. We do not need to prune it.

4. Random Tree
Random forests build lots of bushy trees, and then average them to reduce the variance.
```{r cache=FALSE}
require(randomForest)
set.seed(12345)
rf.training=randomForest(classe~.,data=training,ntree=100, importance=TRUE)
rf.training
varImpPlot(rf.training,)
```
It shows which variable has higher impact on perdiction.

##Out of Sample Accuracy
Random Forest model shows OOB estimate of error rate: 0.72% for the training data. Now lets predict it for out-of sample accuracy.
```{r cache=FALSE}
tree.pred=predict(rf.training,testing,type="class")
predMatrix = with(testing,table(tree.pred,classe))
sum(diag(predMatrix))/sum(as.vector(predMatrix))
```
0.99 means we got a very accurate estimate.


##Conclusion
We can predict the testing data from the website.

```{r cache=FALSE}
answers <- predict(rf.training, testingOrg)
answers
```
Those answers are going to submit to website for grading. It shows that this random forest model did a good job.